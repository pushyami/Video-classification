#
######
### INPUT LAYER ######

######
#TRAIN INPUT LAYER
#

layer{
	name: "data" 
	type: "ImageData"
	top: "data"
	top: "label"
	image_data_param {
		source: "../train11.txt"  #link to all input images
		new_height: 64  #resize to fit into network
		new_width: 64   #resize
		batch_size: 4
}
	include{
		phase: TRAIN
	}
}
layer{
	name: "data" 
	type: "ImageData"
	top: "data2"
	top: "label2"
	image_data_param {
		source: "../train12.txt"  #link to all input images
		new_height: 64  #resize to fit into network
		new_width: 64   #resize
		batch_size: 4
}
	include{
		phase: TRAIN
	}
}
layer{
        name: "data"
        type: "ImageData"
        top: "data3"
        top: "label3"
        image_data_param {
                source: "../train13.txt"  #link to all input images
                new_height: 64  #resize to fit into network
                new_width: 64   #resize
                batch_size: 4
}
        include{
                phase: TRAIN
        }
}
layer{
        name: "data"
        type: "ImageData"
        top: "data4"
        top: "label4"
        image_data_param {
                source: "../train14.txt"  #link to all input images
                new_height: 64  #resize to fit into network
                new_width: 64   #resize
                batch_size: 4
}
        include{
                phase: TRAIN
        }
}

######
### TEST INPUT LAYER
#

layer {
	name: "data"
	type: "ImageData"
	top: "data"
	top: "label"
	image_data_param {
		source: "../test11.txt"
		new_height: 64
		new_width: 64
		batch_size: 4  #testing 100% of images 32*4 -> test_iter
}
	include {
		phase: TEST
	}
}
layer {
        name: "data"
        type: "ImageData"
        top: "data2"
        top: "label2"
        image_data_param {
                source: "../test12.txt"
                new_height: 64
                new_width: 64
                batch_size: 4  #testing 100% of images 32*4 -> test_iter
}
        include {
                phase: TEST
        }
}
layer {
        name: "data"
        type: "ImageData"
        top: "data3"
        top: "label3"
        image_data_param {
                source: "../test13.txt"
                new_height: 64
                new_width: 64
                batch_size: 4  #testing 100% of images 32*4 -> test_iter
}
        include {
                phase: TEST
        }
}
layer {
        name: "data"
        type: "ImageData"
        top: "data4"
        top: "label4"
        image_data_param {
                source: "../test14.txt"
                new_height: 64
                new_width: 64
                batch_size: 4  #testing 100% of images 32*4 -> test_iter
}       
        include {
                phase: TEST
        }
}

###################################################3

######
### CONVOLUTIONAL LAYER
#

layer{
	name: "concat"
	bottom: "data"
	top: "out"
	type: "Concat"
	concat_param{

		axis: 0
	}
}
layer{
        name: "concat"
        bottom: "data2"
        top: "out2"
        type: "Concat"
        concat_param{

                axis: 0
        }
}
layer{
        name: "concat"
        bottom: "data3"
        top: "out3"
        type: "Concat"
        concat_param{

                axis: 0
        }
}
layer{
        name: "concat"
        bottom: "data4"
        top: "out4"
        type: "Concat"
        concat_param{

                axis: 0
        }
}

#########################################################

layer{
	name: "conv1"
	type: "Convolution"
	bottom: "out"
	top: "conv1"	
	param {
		lr_mult:1  #weights
	}
	param {
		lr_mult:2  #biases
	}
	convolution_param { #convolutional layer parameters
		num_output: 64 #number of filters
		pad: 1 #padding on each side of the image
		kernel_size: 3 #3x3 kernel
		stride: 2
		weight_filler {
			type: "xavier" #method of initalizing weights
		}
		bias_filler {
			type: "constant" #method of filling biases
			value: 0 #initialze the biases to 0
		}
	}
}
layer {
	name: "relu1"
	type: "ReLU"
	bottom: "conv1"
	top: "conv1"
}
layer {
	name:"pool1"
	type: "Pooling"
	bottom: "conv1"  ### recheck????????????
	top: "pool1"
	pooling_param {	
		pool: MAX   #try average and stochastic pooling
		kernel_size: 2 #2x2 kernel
		stride: 2 #dimensions cut in half after this layer
	}
}
#########################################################
layer{
        name: "conv12"
        type: "Convolution"
        bottom: "out2"
        top: "conv12"
        param {
                lr_mult:1  #weights
        }
        param {
                lr_mult:2  #biases
        }
        convolution_param { #convolutional layer parameters
                num_output: 64 #number of filters
                pad: 1 #padding on each side of the image
                kernel_size: 3 #3x3 kernel
                stride: 2
                weight_filler {
                        type: "xavier" #method of initalizing weights
                }
                bias_filler {
                        type: "constant" #method of filling biases
                        value: 0 #initialze the biases to 0
                }
        }
}
layer {
        name: "relu12"
        type: "ReLU"
        bottom: "conv12"
        top: "conv12"
}
layer {
        name:"pool12"
        type: "Pooling"
        bottom: "conv12"  ### recheck????????????
        top: "pool12"
        pooling_param {
                pool: MAX   #try average and stochastic pooling
                kernel_size: 2 #2x2 kernel
                stride: 2 #dimensions cut in half after this layer
        }
}
#########################################################
layer{
        name: "conv13"
        type: "Convolution"
        bottom: "out3"
        top: "conv13"
        param {
                lr_mult:1  #weights
        }
        param {
                lr_mult:2  #biases
        }
        convolution_param { #convolutional layer parameters
                num_output: 64 #number of filters
                pad: 1 #padding on each side of the image
                kernel_size: 3 #3x3 kernel
                stride: 2
                weight_filler {
                        type: "xavier" #method of initalizing weights
                }
                bias_filler {
                        type: "constant" #method of filling biases
                        value: 0 #initialze the biases to 0
                }
        }
}
layer {
        name: "relu13"
        type: "ReLU"
        bottom: "conv13"
        top: "conv13"
}
layer {
        name:"pool13"
        type: "Pooling"
        bottom: "conv13"  ### recheck????????????
        top: "pool13"
        pooling_param {
                pool: MAX   #try average and stochastic pooling
                kernel_size: 2 #2x2 kernel
                stride: 2 #dimensions cut in half after this layer
        }
}
#########################################################
layer{
        name: "conv14"
        type: "Convolution"
        bottom: "out4"
        top: "conv14"
        param {
                lr_mult:1  #weights
        }
        param {
                lr_mult:2  #biases
        }
        convolution_param { #convolutional layer parameters
                num_output: 64 #number of filters
                pad: 1 #padding on each side of the image
                kernel_size: 3 #3x3 kernel
                stride: 2
                weight_filler {
                        type: "xavier" #method of initalizing weights
                }
                bias_filler {
                        type: "constant" #method of filling biases
                        value: 0 #initialze the biases to 0
                }
        }
}
layer {
        name: "relu14"
        type: "ReLU"
        bottom: "conv14"
        top: "conv14"
}
layer {
        name:"pool14"
        type: "Pooling"
        bottom: "conv14"  ### recheck????????????
        top: "pool14"
        pooling_param {
                pool: MAX   #try average and stochastic pooling
                kernel_size: 2 #2x2 kernel
                stride: 2 #dimensions cut in half after this layer
        }
}
#########################################################
layer{
        name: "concat"
        bottom: "pool1"
        bottom: "pool12"
        top: "out_1"
        type: "Concat"
        concat_param{

                axis: 0
        }
}
layer{
        name: "concat"
        bottom: "pool13"
        bottom: "pool14"
        top: "out_2"
        type: "Concat"
        concat_param{

                axis: 0
        }
}
layer{
        name: "concat"
        bottom: "label"
        bottom: "label2"
        top: "label_1"
        type: "Concat"
        concat_param{

                axis: 0
        }
}
layer{
        name: "concat"
        bottom: "label3"
        bottom: "label4"
        top: "label_2"
        type: "Concat"
        concat_param{

                axis: 0
        }
}


###################################################3

###################################################3

######
### CONVOLUTIONAL LAYER
#

layer{
	name: "conv2"
	type: "Convolution"
	bottom: "out_1"
	top: "conv2"
	param {
		lr_mult:1  #weights
	}
	param {
		lr_mult:2  #biases
	}
	convolution_param { #convolutional layer parameters
		num_output: 128 #number of filters
		pad: 1 #padding on each side of the image
		kernel_size: 3 #3x3 kernel
		stride: 2	
		weight_filler {
			type: "xavier" #method of initalizing weights
		}
		bias_filler {
			type: "constant" #method of filling biases
			value: 0 #initialze the biases to 0
		}
	}
}

layer {

	name: "relu2"
	type: "ReLU"
	bottom: "conv2"
	top: "conv2"
}

layer {
	name:"pool2"
	type: "Pooling"
	bottom: "conv2"  ### recheck????????????
	top: "pool2"
	pooling_param {	
		pool: MAX   #try average and stochastic pooling
		kernel_size: 2 #2x2 kernel
		stride: 2 #dimensions cut in half after this layer
	}
}


######################################################

layer{
        name: "conv22"
        type: "Convolution"
        bottom: "out_2"
        top: "conv22"
        param {
                lr_mult:1  #weights
        }
        param {
                lr_mult:2  #biases
        }
        convolution_param { #convolutional layer parameters
                num_output: 128 #number of filters
                pad: 1 #padding on each side of the image
                kernel_size: 3 #3x3 kernel
                stride: 2
                weight_filler {
                        type: "xavier" #method of initalizing weights
                }
                bias_filler {
                        type: "constant" #method of filling biases
                        value: 0 #initialze the biases to 0
                }
        }
}

layer {

        name: "relu22"
        type: "ReLU"
        bottom: "conv22"
        top: "conv22"
}

layer {
        name:"pool22"
        type: "Pooling"
        bottom: "conv22"  ### recheck????????????
        top: "pool22"
        pooling_param {
                pool: MAX   #try average and stochastic pooling
                kernel_size: 2 #2x2 kernel
                stride: 2 #dimensions cut in half after this layer
        }
}











#######################################################
### CONVOLUTIONAL LAYER
#

layer{
        name: "concat"
        bottom: "pool2"
        bottom: "pool22"
        top: "output1"
        type: "Concat"
        concat_param{

                axis: 0
        }
}
layer{
        name: "concat"
        bottom: "label_1"
        bottom: "label_2"
        top: "labeloutput"
        type: "Concat"
        concat_param{

                axis: 0
        }
}


###################################################3
######
### FULLY CONNECTED LAYER


#########################################################

######
### FULLY CONNECTED LAYER
#

layer{
	name:"fc2"
	type: "InnerProduct"
	bottom: "output1"
	top: "fc2"
	param {
		lr_mult: 1
	}
	param {
		lr_mult:2
	}
	inner_product_param{
		num_output: 1024  #number of nodes
		weight_filler {
			type:"xavier"
		}
		bias_filler {
			type:"constant" ### value??????????
		}
	}
}

#########################################################
######################################################

######
### RELU LAYER
#

layer {
	name: "relu4"
	type: "ReLU"
	bottom: "fc2"
	top: "fc2"
}

#######################################################
#########################################################

######
### FULLY CONNECTED LAYER
#

layer{
	name:"fc3"
	type: "InnerProduct"
	bottom: "fc2"
	top: "fc3"
	param {
		lr_mult: 1
	}
	param {
		lr_mult:2
	}
	inner_product_param{
		num_output: 6  #number of nodes
		weight_filler {
			type:"xavier"
		}
		bias_filler {
			type:"constant" 
		}
	}
}

#########################################################
##########################################################


######
### SOFTMAX LAYER
#

layer {
	name: "loss"
	type: "SoftmaxWithLoss"
	bottom: "fc3"
	bottom: "labeloutput"
	top: "loss"
	include {
		phase: TRAIN
	}
}

### Softmax without loss for testing

layer {
	bottom: "fc3" 
	top: "prob"
	name: "prob"
	type: "Softmax"
	include {
		phase: TEST
	}
}

##########################################################


######
### ACCURACY LAYER
#

layer {
	name: "accuracy"
	type: "Accuracy"
	bottom: "prob"
	bottom: "labeloutput"
	top: "accuracy/top-1"
	include {
		phase: TEST
	}
}
